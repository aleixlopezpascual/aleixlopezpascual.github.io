<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Aleix López's portfolio</title>
	<link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
	<link rel="icon" href="favicon.ico" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900" rel="stylesheet">
    <link rel="stylesheet" href="libs/font-awesome/css/font-awesome.min.css">
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/styles.css" rel="stylesheet">
</head>

<body>
    <div id="mobile-menu-open" class="shadow-large">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
    <!-- End #mobile-menu-toggle -->
    <header>
        <div id="mobile-menu-close">
            <span>Close</span> <i class="fa fa-times" aria-hidden="true"></i>
        </div>
        <ul id="menu" class="shadow">
            <li>
                <a href="#about">About</a>
            </li>
            <li>
                <a href="#experience">Experience</a>
            </li>
            <li>
                <a href="#education">Education</a>
            </li>
            <li>
                <a href="#projects">Projects</a>
            </li>
	    <li>
                <a href="#publications">Publications</a>
            </li>
	    <li>
                <a href="#honors">Honors & Awards</a>
            </li>
            <li>
                <a href="#skills">Skills</a>
            </li>
            <li>
                <a href="#contact">Contact</a>
            </li>
        </ul>
    </header>
    <!-- End header -->

    <div id="lead">
        <div id="lead-content">
            <h1>Aleix López</h1>
            <h2>Data Scientist at Glovo</h2>
            <a href="resume.pdf" class="btn-rounded-white">See Resume</a>
        </div>
        <!-- End #lead-content -->

        <div id="lead-overlay"></div>

        <div id="lead-down">
            <span>
                <i class="fa fa-chevron-down" aria-hidden="true"></i>
            </span>
        </div>
        <!-- End #lead-down -->
    </div>
    <!-- End #lead -->

    <div id="about">
        <div class="container">
            <div class="row">
                <div class="col-md-4">
                    <h2 class="heading">About Me</h2>
                </div>
                <div class="col-md-8">
                    <p>
                        I am a data scientist with more than 2 years of experience.
                        I am currently working at Glovo, where I worked in two
                        different teams. I spent one year and a half working for the
                        Logistics team, taking care of the routing models used to
                        predict the courier route times. Now I am working in the
                        Central Data Science team, where I help the rest of data
                        scientists to put their models into production and I also
                        create infrastructure to cover general needs of the data
                        scientists. At the same time, I maintain ownership of some
                        machine learning models.
                        <br>
                        <br>
                        Outside of work, I try to help solve meaningful real world
                        problems with data science by participating in Kaggle
                        competitions. I have won several medals and I am ranked in
                        the top 1%  of competitors worldwide. Most of my projects are
                        open and can be found in my GitHub account. I am also an
                        occasional writer in Medium, where I have published for
                        important publications such as Analytics Vidhya.
                        <br>
                        <br>
                        I consider myself a very complete data scientist. On one hand,
                        I am strong in the field of data science; I have great
                        knowledge in machine learning and deep learning, as well as
                        good skills in coding. I am completely connected with the
                        state-of-the-art in machine learning and I am constantly
                        learning in this ever-evolving field. On the other hand,
                        I have a solid knowledge and experience in software engineering
                        and productionalization of machine learning models, which
                        also makes me a good fit for a machine learning engineer role.
                    </p>
                </div>
            </div>
        </div>
    </div>
    <!-- End #about -->

    <div id="experience" class="background-alt">
        <h2 class="heading">Experience</h2>
        <div id="experience-timeline">
		
	     <div data-date="July 2019 – Present">
                <h3>Data Scientist</h3>
                <h4>Glovo</h4>
                <p>
                    I worked in two different teams. I spent one year and a half
                    working for the Logistics team, taking care of the routing models
                    used to predict the courier route times. Now I am working in the
                    Central Data Science team, where I help the rest of data scientists
                    to put their models into production and I also create infrastructure
                    to cover general needs of the data scientists. At the same time,
                    I maintain ownership of some machine learning models.
		        </p>
            </div>
		
	    <div data-date="June 2019 – Present">
                <h3>Writer</h3>
                <h4>Medium</h4>
                <p>
                    Sharing concepts, ideas and codes about data science,
                    machine learning, programming, visualization and AI.
                    <br>
                    <br>
                    I have published for important publications such as Analytics Vidhya.
                    <br>
                    <br>
                    https://medium.com/@aleixlopez
                </p>
            </div>
		
	    <div data-date="September 2018 – Present">
                <h3>Kaggle competitor</h3>
                <h4>Kaggle</h4>
                <p>
                    Active participant in Kaggle competitions in order to practice with
                    end-to-end projects and keep up with the state-of-the-art algorithms and methods.
                    <br>
                    <br>
                    I have won several medals and I am ranked in the top 1% of
                    competitors worldwide. For further information about the
                    competitions in which I have participated, refer to the projects
                    and awards sections.
                    <br>
                    <br>
                    https://www.kaggle.com/aleixlopez
                </p>
            </div>
        </div>
    </div>
    <!-- End #experience -->

    <div id="education">
        <h2 class="heading">Education</h2>	    
        <div class="education-block">
            <h3>Data Science</h3>
            <span class="education-date">Sept 2018 - July 2019</span>
            <h4>Self-Education</h4>
            <p>
                High-quality education from Kaggle, Coursera, edX, Udemy, DataCamp,
                Codecademy, freeCodeCamp and books.
                <br>
                Courses:
            </p>
            <ul>
                <li>Python for Data Science (Numpy, Pandas, SciPy, SymPy...).</li>
                <li>R Programming.</li>
                <li>Data Visualization (Matplotlib, Pandas, Seaborn...).</li>
                <li>SQL (MySQL, SQL Server, PostgreSQL...).</li>
                <li>NoSQL (MongoDB).</li>
                <li>Distributed Computing Frameworks (Hadoop and Spark).</li>
                <li>Machine Learning (scikit-learn, Spark MLlib...).</li>
                <li>Deep Learning (TensorFlow, PyTorch, Keras...).</li>
                <li>Business Intelligence tools (Looker, Tableau).</li>
                <li>Cloud Computing Services (AWS).</li>
            </ul>

        </div>
        <!-- End .education-block -->
	<div class="education-block">
            <h3>Master of Science in High Energy Physics, Astrophysics and Cosmology</h3>
            <h4>Universitat Autónoma de Barcelona</h4>
	    <span class="education-date">Sept 2017 - Sept 2018</span>
            <p>
                High Energy Physics itinerary.
                <br>
                First Class Honours.
                <br>
                Statistics and Data Analysis projects.
            </p>
        </div>
        <!-- End .education-block -->
	<div class="education-block">
            <h3>Bachelor of Science in Physics</h3>
            <span class="education-date">Sept 2013 - July 2017</span>
            <h4>Universitat de Barcelona</h4>
            <p>
                Major in Fundamental Physics.
                <br>
                First Class Honours.
            </p>
        </div>
        <!-- End .education-block -->
    </div>
    <!-- End #education -->
		   
    <div id="projects" class="background-alt">
        <h2 class="heading">Projects</h2>
        <div class="container">
            <div class="row">

                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/riiid_2020.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>2020 Riiid! Answer Correctness Prediction</h3>
                        <p>
                            (December 2020) In this competition, you had to create algorithms for "Knowledge Tracing,"
                            the modeling of student knowledge over time. The goal was to accurately predict
                            how students will perform on future interactions (binary classification problem
                            evaluated on AUC). In order to do so, the EdNet dataset was used;
                            the world’s largest open database for AI education containing more than 100 million
                            student interactions. The model applied is an ensemble of 4 LGBMs + 1 SAKT transformer.
                        </p>
                        <a href="https://github.com/aleixlopezpascual/riiid-test-answer-prediction">View Project</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->

                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/halite.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>2020 Halite by Two Sigma</h3>
                        <p>
                            (September 2020) Halite is an online multiplayer game created by Two Sigma.
                            In the game, four participants command ships to collect an energy source called halite.
                            The player with the most halite at the end of the game wins. In this competition,
                            you had to write your own intelligent bot to play the game. Due to the arbitrary
                            number of units (ships/bases), a long episode duration, a dynamic opponent pool and
                            a finite computation time, the problem was very difficult to tackle using Deep RL.
                            Therefore, I decided to apply heuristics.
                        </p>
                        <a href="https://github.com/aleixlopezpascual/halite-by-two-sigma-2020">View Project</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->

		        <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/siim-isic_melanoma_classification.png" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>2020 SIIM-ISIC Melanoma Classification</h3>
                        <p>
                            (August 2020) In this competition, you had to identify melanoma in images of skin lesions.
		                    This is a very challenging image classification task as seen by looking at the images provided.
			                The dataset contains images and metadata. On one hand, the images are transformed to TFRecords
                            and used to train an ensemble of EffNets with different parameters (metadata, upsampling,
                            crop augmentation, image size, TTA...). On the other hand, the metadata is used to train an XGBoost.
                            Both predictions are combined using a weighted arithmetic mean.
                        </p>
                        <a href="https://github.com/aleixlopezpascual/siim-isic-melanoma-classification">View Project</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->   
		    
		        <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/instant_gratification.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3> 2019 Kaggle Instant Gratification</h3>
                        <p>
                            (June 2019) In this competition you had to solve a binary classification problem
                            evaluated with AUC. The key factor of this contest was to infer that the data was
                            synthetic, and that you could reverse-engineer how the data set was generated.
                            The data set appeared to be 512 data sets concatenated where each sub dataset was
                            believed to be created by Sklearn's make_classification. EDA suggested that the
                            data resided in 33 + x (where 0 <= x <= 14) dimensional space within 6 hyper-ellipsoids.
                            Each hyper-ellipsoid corresponded to a multivariate Gaussian distribution.
                            Based on this information, I decided to apply Quadratic Discriminant Anlysis,
                            Pseudo Labeling and Gaussian Mixture Models.
                        </p>
                        <a href="https://github.com/aleixlopezpascual/kaggle-instant-gratification">View Project</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->    
		    
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/Hypothesis_testing.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>Hypothesis Testing and Unfolding</h3>
                        <p>
                            (Jan 2018) We select signal-enriched subsamples out of the data sample
                            (signal + background) and background control sample (only background).
                            In order to do so, we construct some test statistics to investigate
                            the level of agreement with the hypothesis and we compare its performance.
                            We use the spectral information to increase the significance
			                of signal detection. Finally, we simulate and solve an unfolding problem.
                        </p>
                        <a href="https://github.com/aleixlopezpascual/aleixlopezpascual.github.io/tree/master/Projects/Hypothesis%20Testing%20and%20Unfolding">View Project</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->

                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/Parameter estimation.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>Parameter Estimation and Bayesian Statistics</h3>
                        <p>
                            (Dec 2017) Given data from an LHC experiment produced in a certain decay
                            channel of the Higgs particle, we compute the confidence interval for
                            different confidence levels. We perform an exhaustive parameter estimation and we
                            construct the Bayesian posterior pdf using a Monte Carlo simulation.
                            Finally, we sample the posterior pdf using a Markov chain Monte Carlo
                            with a Metropolis-Hastings sampler and a Gibbs sampler.
                        </p>
                        <a href="https://github.com/aleixlopezpascual/aleixlopezpascual.github.io/tree/master/Projects/Parameter%20Estimation%20and%20Bayesian%20Statistics">View Project</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->
		    
		
		<div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/prob and mc.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>Probability and Monte Carlo Techniques</h3>
                        <p>
                            (Nov 2017) The angular distribution of the electrons produced in muon decays
                            is described by some known distribution. This theory predicts the probability
                            for an event to occur as a function of the scattering angle and the muon polarization (P).
			                The main purpose of this project is to estimate P. We do it in two different ways:
                            computing the basic statistical momentums and finding the most probable value of P
                            using conditional probabilities. Furthermore, we elaborate some tests in order to verify the
		                    process (Law of large numbers, Student's t-distribution, CLT and Pearson's chi-squared test).
                        </p>
                        <a href="https://github.com/aleixlopezpascual/aleixlopezpascual.github.io/tree/master/Projects/Probability%20and%20Monte%20Carlo%20Techniques">View Project</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->
            </div>
        </div>
    </div>
    <!-- End #projects -->
	
    <div id='publications' class="optional-section">
        <h2 class="heading">Publications</h2>

	<div class="container">
            <div class="row">
		    
		<div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/Veneziano amplitudes.png" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>Veneziano amplitudes for the light-by-light scattering</h3>
                        <p>
                            (Sep 2018) The anomalous magnetic moment of the muon induced by
                            the pseudoscalar-pole contribution to the hadronic light-by-light
                            scattering is considered using a description of the transition form factors in
                            the pion-pole approximation based on the Dual-Large Number of colors QCD model.
                            This framework improves considerably the VMD and LMD results by summing
                            up all the infinite number of zero width resonances that appear in the
                            large color limit, with masses and couplings fixed so that the form factors
                            become Euler Beta functions of the Veneziano type.
                            We have obtained results which substantially increase the discrepancy
                            of 3-4 sigma between experiment and theory that has been obtained from the most recent
                            models and data. Therefore, it is a sign of New Physics more promising than before.
                        </p>
                        <a href="Publications/Veneziano amplitudes for the light-by-light scattering.pdf">View Publication</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->
		    
		    
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/Identification of strongly correlated states of cold atoms.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>Identification of strongly correlated states of cold atoms</h3>
                        <p>
                            (Jun 2017) Using a small sample of cold bosonic atoms submitted to a strong artificial magnetic
                            field, we obtain the ground state of the system in the lowest Landau level. Our goal is to identify
                            the ground state obtained with the known Laughlin state. The calculations have been done by
                            exact diagonalization of the corresponding Hamiltonian. The obtained ground state is a strongly
                            correlated state with zero interaction. This state shows all of the characteristics familiar from the
                            fractional quantum Hall effect.  
                        </p>
                        <a href="Publications/Identification of strongly correlated states of cold atoms.pdf">View Publication</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->
		    
            </div>
        </div>
    </div>
    <!-- End #publications -->
	    
	
    <div id='honors' class="optional-section background-alt">
        <h2 class="heading">Honors & Awards</h2>

        <div class="education-block">
            <h3>Riiid! Answer Correctness Prediction - Bronze medal</h3>
            <span class="education-date">Dec 2020</span>
            <h4>Kaggle</h4>
            <ul>
                In this competition, you had to create algorithms for "Knowledge Tracing,"
                the modeling of student knowledge over time. The goal was to accurately predict
                how students will perform on future interactions (binary classification problem
                evaluated on AUC). In order to do so, the EdNet dataset was used;
                the world’s largest open database for AI education containing more than 100 million
                student interactions. The model applied is an ensemble of 4 LGBMs + 1 SAKT transformer.
            </ul>
        </div>
        <!-- End .education-block -->

        <div class="education-block">
            <h3>Halite by Two Sigma - Silver medal</h3>
            <span class="education-date">Sep 2020</span>
            <h4>Kaggle</h4>
            <ul>
                Halite is an online multiplayer game created by Two Sigma.
                In the game, four participants command ships to collect an energy source called halite.
                The player with the most halite at the end of the game wins. In this competition,
                you had to write your own intelligent bot to play the game. Due to the arbitrary
                number of units (ships/bases), a long episode duration, a dynamic opponent pool and
                a finite computation time, the problem was very difficult to tackle using Deep RL.
                Therefore, I decided to apply heuristics.
            </ul>
        </div>
        <!-- End .education-block -->
	    
        <div class="education-block">
            <h3>SIIM-ISIC Melanoma Classification - Silver medal</h3>
            <span class="education-date">Aug 2020</span>
            <h4>Kaggle</h4>
            <ul>
                In this competition, you had to identify melanoma in images of skin lesions.
                This is a very challenging image classification task as seen by looking at the images provided.
                The dataset contains images and metadata. On one hand, the images are transformed to TFRecords
                and used to train an ensemble of EffNets with different parameters (metadata, upsampling,
                crop augmentation, image size, TTA...). On the other hand, the metadata is used to train an XGBoost.
                Both predictions are combined using a weighted arithmetic mean.
            </ul>
        </div>
        <!-- End .education-block -->
	    
    </div>
    <!-- End .optional-section -->
	
    <div id="skills">
        <h2 class="heading">Technical Skills</h2>
        <ul>
            <li>Python</li>
            <li>SQL (MySQL, SQL Server, PostgreSQL...)</li>
	    <li>Data Science libraries (Numpy, Pandas, SciPy, SymPy...)</li>
	    <li>Data Visualization (Matplotlib, Pandas, Seaborn...)</li>
	    <li>Distributed Computing Frameworks (Hadoop, Spark...)</li>
	    <li>Machine Learning (scikit-learn, Spark MLlib...)</li>
	    <li>Deep Learning (TensorFlow, Keras...)</li>
	    <li>Business Intelligence tools (Tableau)</li>
	    <li>Cloud Computing Services (AWS)</li>
	    <li>Cloudera</li>
	    <li>Containers</li>
	    <li>Docker</li>
	    <li>NoSQL (MongoDB)</li>
	    <li>Excel</li>
	    <li>R</li>
	    <li>Fortran</li>
	    <li>Gnuplot</li>
	    <li>Version Control (Git)</li>
	    <li>Mathematica</li>
	    <li>Markdown</li>
	    <li>Bash</li>
	    <li>LaTex</li>
	    <li>Visual Studio</li>
	    <li>VirtualBox</li>
	    <li>PyCharm</li>
        </ul>
    </div>
    <!-- End #skills -->

   <div id="skills" class="background-alt">
   <h2 class="heading">Soft Skills</h2>
        <ul>
            <li>Resiliency</li>
	    <li>Versatile</li>
	    <li>Time management</li>
	    <li>Requires minimal supervision</li>
	    <li>Self-Motivation</li>
	    <li>Competitive</li>
	    <li>Verbal and written communication</li>
	    <li>Critical thinking</li>
	    <li>Reasoning</li>
	    <li>Problem solving</li>
	    <li>Research</li>
	    <li>Identify and predict trends and patterns</li>
	    <li>Report writing</li>
	    <li>Scientific programming</li>
        </ul>
    </div>
    <!-- End #soft skills -->
	
    <div id="contact">
        <h2>Get in Touch</h2>
        <div id="contact-form">
            <form method="POST" action="https://formspree.io/cheals@outlook.com">
                <input type="hidden" name="_subject" value="Contact request from personal website" />
                <input type="email" name="_replyto" placeholder="Your email" required>
                <textarea name="message" placeholder="Your message" required></textarea>
                <button type="submit">Send</button>
            </form>
        </div>
        <!-- End #contact-form -->
    </div>
    <!-- End #contact -->

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-sm-5 copyright">
                    <p>
                        Copyright &copy; 2021 Aleix López Pascual
                    </p>
                </div>
                <div class="col-sm-2 top">
                    <span id="to-top">
                        <i class="fa fa-chevron-up" aria-hidden="true"></i>
                    </span>
                </div>
                <div class="col-sm-5 social">
                    <ul>
                        <li>
                            <a href="https://github.com/aleixlopezpascual" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://stackoverflow.com/users/11566559/aleix-l%C3%B3pez" target="_blank"><i class="fa fa-stack-overflow" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://www.linkedin.com/in/aleixlopezpascual/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </footer>
    <!-- End footer -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="js/scripts.min.js"></script>
</body>

</html>
